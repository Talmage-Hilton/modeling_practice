---
title: "modeling_practice"
author: "Talmage Hilton"
date: "2025-05-22"
output:
  html_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
library(tidyverse)
library(vroom)

# Read in data
df <- vroom("synthetic_student_habits_performance.csv")
```


### EDA

```{r}
# Drop student_id and parental_education_level columns
df <- df %>% select(-student_id, -parental_education_level)

# Encode dummy variables for 'part_time_job' and 'extracurricular_participation' (Yes -> 1, No -> 0)
df <- df %>%
  mutate(
    part_time_job = ifelse(part_time_job == "Yes", 1, 0),
    extracurricular_participation = ifelse(extracurricular_participation == "Yes", 1, 0)
  )

# Create dummy variables for gender, diet_quality, and internet_quality, dropping first level
# We'll use model.matrix for this and convert back to data.frame

# Helper function to get dummies dropping first category
get_dummies <- function(data, varname) {
  mat <- model.matrix(~ get(varname) - 1, data = data)
  # Drop first column
  mat <- mat[, -1, drop = FALSE]
  # Clean column names
  colnames(mat) <- gsub("get\\(varname\\)", varname, colnames(mat))
  as.data.frame(mat)
}

# Add gender dummies
gender_dummies <- get_dummies(df, "gender")
df <- cbind(df %>% select(-gender), gender_dummies)

# Add diet_quality dummies
diet_dummies <- get_dummies(df, "diet_quality")
df <- cbind(df %>% select(-diet_quality), diet_dummies)

# Add internet_quality dummies
internet_dummies <- get_dummies(df, "internet_quality")
df <- cbind(df %>% select(-internet_quality), internet_dummies)

# Reorder columns to put exam_score first
df <- df %>% select(exam_score, everything())

# View first few rows
head(df)
```

```{r, message=FALSE, warning=FALSE}
library(patchwork)

# Histograms

# List of columns to plot
cols_to_plot <- c(
  "exam_score", "age", "study_hours_per_day", "social_media_hours", "netflix_hours",
  "attendance_percentage", "sleep_hours", "exercise_frequency", "mental_health_rating"
)

# Create a list of histogram plots
hist_list <- lapply(cols_to_plot, function(col) {
  ggplot(df, aes_string(x = col)) +
    geom_histogram(binwidth = NULL, fill = "skyblue", color = "black") +
    labs(title = paste(col), x = col, y = "Count") +
    theme_minimal()
})

# Arrange in grid: choose number of columns
ncols <- 3
hist_grid <- wrap_plots(hist_list, ncol = ncols)

# Show the grid
print(hist_grid)
```

```{r}
# Scatterplots

# Define predictors and response
predictors <- c(
  "age", "study_hours_per_day", "social_media_hours", "netflix_hours",
  "attendance_percentage", "sleep_hours", "exercise_frequency",
  "mental_health_rating"
)
response <- "exam_score"

# Create scatterplots
scatter_list <- lapply(predictors, function(pred) {
  ggplot(df, aes_string(x = pred, y = response)) +
    geom_point(color = "dodgerblue2", size = 0.5, alpha = 0.7) +
    labs(title = pred, x = pred, y = response) +
    theme_minimal()
})

# Arrange in grid: choose number of columns
ncols <- 4
scatter_grid <- wrap_plots(scatter_list, ncol = ncols)

# Display the grid
print(scatter_grid)
```

```{r, warning=FALSE, message=FALSE}
library(reshape2)

# Correlation heatmap (looks great!)

# Columns to include
cols_to_plot <- c(
  "exam_score", "age", "study_hours_per_day", "social_media_hours", "netflix_hours",
  "attendance_percentage", "sleep_hours", "exercise_frequency", "mental_health_rating"
)

# Compute correlation matrix
corr_matrix <- cor(df[cols_to_plot], use = "complete.obs")

# Melt the matrix to long format
melted_corr <- melt(corr_matrix)

# Enforce factor levels to preserve order in plot
melted_corr$Var1 <- factor(melted_corr$Var1, levels = rev(cols_to_plot))  # y-axis
melted_corr$Var2 <- factor(melted_corr$Var2, levels = cols_to_plot)       # x-axis

# Plot heatmap
ggplot(melted_corr, aes(x = Var2, y = Var1, fill = value)) +
  geom_tile(color = "white") +
  scale_fill_gradient2(
    low = "blue", mid = "white", high = "red", midpoint = 0, limit = c(-1, 1),
    name = "Correlation"
  ) +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1),
    panel.grid = element_blank()
  ) +
  labs(title = "Correlation Heatmap", x = "", y = "")
```








# **LINEAR MODELS**








### **OLS**

```{r}
model <- lm(exam_score ~ age + study_hours_per_day + social_media_hours + netflix_hours + part_time_job + attendance_percentage + sleep_hours + exercise_frequency + mental_health_rating + extracurricular_participation + genderMale + genderOther + diet_qualityGood + diet_qualityPoor + internet_qualityGood + internet_qualityPoor, data = df)

summary(model)

# Could also make them factors and do it the classic way instead of one-hot encoding, results are identical

# df$gender <- as.factor(df$gender)
# df$part_time_job <- as.factor(df$part_time_job)
# df$diet_quality <- as.factor(df$diet_quality)
# df$internet_quality <- as.factor(df$internet_quality)
# df$extracurricular_participation <- as.factor(df$extracurricular_participation)
# model <- lm(exam_score ~ ., data=df)
```





### **LASSO**

```{r, warning=FALSE, message=FALSE}
library(glmnet)
library(caret)
library(dplyr)

# Define predictors and response
X <- df %>%
  select(
    age, study_hours_per_day, social_media_hours, netflix_hours,
    part_time_job, attendance_percentage, sleep_hours,
    exercise_frequency, mental_health_rating, extracurricular_participation,
    genderMale, genderOther, diet_qualityGood, diet_qualityPoor,
    internet_qualityGood, internet_qualityPoor
  ) %>% as.matrix()

y <- df$exam_score

# Train-test split (80/20)
set.seed(123)
train_index <- createDataPartition(y, p = 0.8, list = FALSE)
X_train <- X[train_index, ]
X_test <- X[-train_index, ]
y_train <- y[train_index]
y_test <- y[-train_index]

# Scale predictors (standardize)
scaler <- preProcess(X_train, method = c("center", "scale"))
X_train_scaled <- predict(scaler, X_train)

# Fit LASSO model (alpha = 1 for LASSO, lambda = 0.1)
lasso_model <- glmnet(X_train_scaled, y_train, alpha = 1, lambda = 0.1)

# Extract coefficients
coef(lasso_model)
```

```{r}
# Now run OLS with those coefficients
summary(lm(exam_score ~ age + study_hours_per_day + social_media_hours + netflix_hours + part_time_job + attendance_percentage + sleep_hours + exercise_frequency + mental_health_rating + genderOther + diet_qualityGood + internet_qualityGood, data=df))
```





### **Polynomial**

```{r}
model <- lm(exam_score ~ age + I(age^2) + study_hours_per_day + I(study_hours_per_day^2) + I(study_hours_per_day^3) + social_media_hours + netflix_hours + part_time_job + attendance_percentage + sleep_hours + exercise_frequency + mental_health_rating + extracurricular_participation + genderMale + genderOther + diet_qualityGood + diet_qualityPoor + internet_qualityGood + internet_qualityPoor, data = df)

summary(model)
```

```{r}
# The poly() function also works

model <- lm(exam_score ~ poly(age, 2, raw=TRUE) + poly(study_hours_per_day, 3, raw=TRUE) + social_media_hours + netflix_hours + part_time_job + attendance_percentage + sleep_hours + exercise_frequency + mental_health_rating + extracurricular_participation + genderMale + genderOther + diet_qualityGood + diet_qualityPoor + internet_qualityGood + internet_qualityPoor, data = df)

summary(model)
```






### **Natural Splines**

```{r}
# Load required package
library(splines)

# Define the model formula with natural splines
model <- lm(
  exam_score ~ ns(age, df = 4) + ns(study_hours_per_day, df = 3) +
    social_media_hours + netflix_hours + part_time_job + attendance_percentage +
    sleep_hours + exercise_frequency + mental_health_rating +
    extracurricular_participation + genderMale + genderOther +
    diet_qualityGood + diet_qualityPoor + internet_qualityGood + internet_qualityPoor,
  data = df
)

# Summary of the model
summary(model)
```





### **GAM**

```{r, warning=FALSE, message=FALSE}
library(mgcv)

# Fit GAM model
gam_model <- gam(
  exam_score ~ s(age, k = 4) + s(study_hours_per_day, k = 3) +
    social_media_hours + netflix_hours + part_time_job + attendance_percentage +
    sleep_hours + exercise_frequency + mental_health_rating +
    extracurricular_participation + genderMale + genderOther +
    diet_qualityGood + diet_qualityPoor + internet_qualityGood + internet_qualityPoor,
  data = df,
  method = "REML"  # recommended smoothing parameter estimation method
)

# Summary of the GAM model
summary(gam_model)

# Plot smooth terms
# plot(gam_model, pages = 1, rug = TRUE)
```





### **Logistic Regression**

```{r, message = FALSE}
# Clean up data (get rid of User ID column and encode Gender variable)
ads <- vroom("social_network_ads.csv")
ads <- ads[c(2:5)]
ads["Gender"] <- ifelse(ads["Gender"] == "Male", 1, 0)

# Make Purchased a factor
ads$Purchased <- as.factor(ads$Purchased)

model <- glm(Purchased ~ Gender + Age + EstimatedSalary, data=ads, family=binomial)
summary(model)
```








# **MACHINE LEARNING MODELS**









### **K Nearest Neighbors**

```{r}
# Continuous Response

# Load required packages
library(FNN)       # For KNN regression
library(caret)     # For data splitting and preprocessing
library(dplyr)

# Ensure the categorical variables are numeric
# (Assuming you've already transformed them into: genderMale, genderOther, etc.)
X <- df %>%
  select(age, study_hours_per_day, social_media_hours, netflix_hours,
         part_time_job, attendance_percentage, sleep_hours,
         exercise_frequency, mental_health_rating, extracurricular_participation,
         genderMale, genderOther, diet_qualityGood, diet_qualityPoor,
         internet_qualityGood, internet_qualityPoor)

y <- df$exam_score

# Train/Test split (70/30)
set.seed(123)
train_index <- createDataPartition(y, p = 0.7, list = FALSE)
X_train <- X[train_index, ]
X_test  <- X[-train_index, ]
y_train <- y[train_index]
y_test  <- y[-train_index]

# Scale the predictors
X_train_scaled <- scale(X_train)
X_test_scaled  <- scale(X_test, center = attr(X_train_scaled, "scaled:center"),
                                  scale = attr(X_train_scaled, "scaled:scale"))

# Fit KNN model (k = 5)
knn_pred_train <- knn.reg(train = X_train_scaled, test = X_train_scaled, y = y_train, k = 5)$pred
knn_pred_test  <- knn.reg(train = X_train_scaled, test = X_test_scaled,  y = y_train, k = 5)$pred

# Calculate RMSE and R-squared
rmse_train <- sqrt(mean((y_train - knn_pred_train)^2))
rmse_test <- sqrt(mean((y_test - knn_pred_test)^2))

# Output results
cat(sprintf("In-sample RMSE: %.4f\n", rmse_train))
cat(sprintf("Out-of-sample RMSE: %.4f\n", rmse_test))
```

```{r, message=FALSE}
# Binary Response

# Load required packages
library(FNN)
library(caret)
library(pROC)
library(dplyr)
library(ggplot2)

# Ensure 'Purchased' is a factor (0/1)
ads$Purchased <- as.factor(ads$Purchased)

# Select predictors and target
X <- ads %>% select(Gender, Age, EstimatedSalary)
y <- ads$Purchased

# Split into training and testing
set.seed(123)
train_index <- createDataPartition(y, p = 0.7, list = FALSE)
X_train <- X[train_index, ]
X_test <- X[-train_index, ]
y_train <- y[train_index]
y_test <- y[-train_index]

# Standardize predictors
X_train_scaled <- scale(X_train)
X_test_scaled <- scale(X_test, center = attr(X_train_scaled, "scaled:center"),
                                  scale = attr(X_train_scaled, "scaled:scale"))

### --- In-Sample Predictions --- ###
knn_train <- knn(train = X_train_scaled, test = X_train_scaled, cl = y_train, k = 5, prob = TRUE)
train_preds <- knn_train
train_probs <- ifelse(train_preds == "1", attr(knn_train, "prob"), 1 - attr(knn_train, "prob"))
train_accuracy <- mean(train_preds == y_train)
train_auc <- auc(roc(as.numeric(as.character(y_train)), train_probs))

### --- Out-of-Sample Predictions --- ###
knn_test <- knn(train = X_train_scaled, test = X_test_scaled, cl = y_train, k = 5, prob = TRUE)
test_preds <- knn_test
test_probs <- ifelse(test_preds == "1", attr(knn_test, "prob"), 1 - attr(knn_test, "prob"))
test_accuracy <- mean(test_preds == y_test)
test_auc <- auc(roc(as.numeric(as.character(y_test)), test_probs))

### --- Print Results --- ###
cat(sprintf("In-sample Accuracy: %.4f\n", train_accuracy))
cat(sprintf("In-sample AUC: %.4f\n", train_auc))
cat(sprintf("Out-of-sample Accuracy: %.4f\n", test_accuracy))
cat(sprintf("Out-of-sample AUC: %.4f\n", test_auc))

# Optional: Print confusion matrix for test set
confusionMatrix(test_preds, y_test, positive = "1")

# Compute ROC object for test set
roc_obj <- roc(as.numeric(as.character(y_test)), test_probs)

# Convert ROC object to data frame
roc_df <- data.frame(
  specificities = rev(roc_obj$specificities),  # FPR = 1 - specificity
  TruePositiveRate = rev(roc_obj$sensitivities)
)

# Plot using ggplot2
ggplot(roc_df, aes(x = 1 - specificities, y = TruePositiveRate)) +
  geom_line(color = "#1c61b6", size = 1.2) +
  geom_abline(slope = 1, intercept = 0, linetype = "dashed") +
  labs(
    title = paste0("ROC Curve for KNN (AUC = ", round(auc(roc_obj), 4), ")"),
    x = "False Positive Rate (1 - Specificity)",
    y = "True Positive Rate (Sensitivity)"
  ) +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5))
```






### **Support Vector Machines**

```{r}
# Continuous Response

# Load necessary libraries
library(e1071)     # For SVR
library(caret)     # For train/test split and evaluation
library(dplyr)

# Define predictors and response
X <- df %>% select(age, study_hours_per_day, social_media_hours, netflix_hours,
                   part_time_job, attendance_percentage, sleep_hours,
                   exercise_frequency, mental_health_rating, extracurricular_participation,
                   genderMale, genderOther, diet_qualityGood, diet_qualityPoor,
                   internet_qualityGood, internet_qualityPoor)

y <- df$exam_score

# Train/test split
set.seed(123)
train_index <- createDataPartition(y, p = 0.7, list = FALSE)
X_train <- X[train_index, ]
X_test  <- X[-train_index, ]
y_train <- y[train_index]
y_test  <- y[-train_index]

# Combine X and y for training since svm() needs formula interface or combined data
train_data <- cbind(X_train, exam_score = y_train)
test_data  <- cbind(X_test,  exam_score = y_test)

# Fit SVR model (default is radial basis kernel)
svr_model <- svm(exam_score ~ ., data = train_data, kernel = "radial")

# Predict
y_pred_train <- predict(svr_model, newdata = X_train)
y_pred_test  <- predict(svr_model, newdata = X_test)

# Compute RMSE
rmse_train <- sqrt(mean((y_train - y_pred_train)^2))
rmse_test  <- sqrt(mean((y_test - y_pred_test)^2))

# Output results
cat(sprintf("In-sample RMSE: %.4f\n", rmse_train))
cat(sprintf("Out-of-sample RMSE: %.4f\n", rmse_test))
```

```{r, message=FALSE}
# Binary Response

# Load necessary libraries
library(e1071)       # For svm()
library(caret)       # For train/test split
library(pROC)        # For AUC calculation

# Prepare data (make sure Gender is numeric or already dummy coded)
X <- ads[, c("Gender", "Age", "EstimatedSalary")]
y <- ads$Purchased

# Ensure Gender is numeric (if it's a factor)
if (is.factor(X$Gender)) {
  X$Gender <- as.numeric(X$Gender)  # or use model.matrix to one-hot encode if needed
}

# Train/test split
set.seed(123)
train_index <- createDataPartition(y, p = 0.7, list = FALSE)
X_train <- X[train_index, ]
X_test  <- X[-train_index, ]
y_train <- y[train_index]
y_test  <- y[-train_index]

# Combine X and y for svm() training
train_data <- cbind(X_train, Purchased = as.factor(y_train))  # Response must be factor for classification
test_data  <- cbind(X_test, Purchased = as.factor(y_test))

# Train SVM with radial kernel and probability estimates
svm_model <- svm(Purchased ~ ., data = train_data, kernel = "radial", probability = TRUE)

# Predictions (class labels)
y_train_pred <- predict(svm_model, newdata = X_train)
y_test_pred  <- predict(svm_model, newdata = X_test)

# Probabilities
y_train_prob <- attr(predict(svm_model, newdata = X_train, probability = TRUE), "probabilities")[, 2]
y_test_prob  <- attr(predict(svm_model, newdata = X_test, probability = TRUE), "probabilities")[, 2]

# Accuracy
train_acc <- mean(y_train_pred == y_train)
test_acc  <- mean(y_test_pred == y_test)

# AUC
train_auc <- auc(y_train, y_train_prob)
test_auc  <- auc(y_test, y_test_prob)

# Output results
cat(sprintf("In-sample Accuracy: %.4f\n", train_acc))
cat(sprintf("In-sample AUC: %.4f\n", train_auc))
cat(sprintf("Out-of-sample Accuracy: %.4f\n", test_acc))
cat(sprintf("Out-of-sample AUC: %.4f\n", test_auc))

cat("\nConfusion Matrix - Testing Data:\n")
print(confusionMatrix(y_test_pred, as.factor(y_test)))
```






### **Decision Tree (CART)**

```{r, warning=FALSE, message=FALSE}
# Continuous Response

# Load necessary libraries
library(rpart)
library(rpart.plot)
library(Metrics)  # for RMSE
set.seed(123)

# Ensure your data frame is numeric where needed
# If your df is not already loaded, load it here

# Define features and target
features <- c('age', 'study_hours_per_day', 'social_media_hours', 'netflix_hours',
              'part_time_job', 'attendance_percentage', 'sleep_hours',
              'exercise_frequency', 'mental_health_rating', 'extracurricular_participation',
              'genderMale', 'genderOther', 'diet_qualityGood', 'diet_qualityPoor',
              'internet_qualityGood', 'internet_qualityPoor')

X <- df[, features]
y <- df$exam_score

# Combine features and target into one data frame
data <- cbind(X, exam_score = y)

# Split into training and testing sets (70/30)
sample_idx <- sample(seq_len(nrow(data)), size = 0.7 * nrow(data))
train_data <- data[sample_idx, ]
test_data  <- data[-sample_idx, ]

# Fit regression tree
reg_tree <- rpart(exam_score ~ ., data = train_data, method = "anova", control = rpart.control(maxdepth = 3))

# Predictions
y_train_pred <- predict(reg_tree, newdata = train_data)
y_test_pred <- predict(reg_tree, newdata = test_data)

# RMSE
rmse_train <- rmse(train_data$exam_score, y_train_pred)
rmse_test <- rmse(test_data$exam_score, y_test_pred)

cat(sprintf("Regression Tree - In-sample RMSE: %.4f\n", rmse_train))
cat(sprintf("Regression Tree - Out-of-sample RMSE: %.4f\n", rmse_test))

# Plot the tree
rpart.plot(reg_tree, main = "Regression Tree", extra = 101, type = 2, under = TRUE, faclen = 0)
```

```{r, message=FALSE, warning=FALSE}
# Binary Response

# Load necessary libraries
library(rpart)
library(rpart.plot)
library(caret)      # for createDataPartition
library(pROC)       # for AUC

# Assume your data frame is called ads
# Make sure 'Gender' and other features are numeric or factors as needed

# Example: Convert Gender to factor if not already
ads$Gender <- as.factor(ads$Gender)
ads$Purchased <- as.factor(ads$Purchased)  # Target as factor

# Define features and target
X <- ads[, c("Gender", "Age", "EstimatedSalary")]
y <- ads$Purchased

# Train/test split: 70% train, 30% test
set.seed(123)
train_idx <- createDataPartition(y, p = 0.7, list = FALSE)
train_data <- ads[train_idx, ]
test_data <- ads[-train_idx, ]

# Fit classification tree with max depth = 3
# In rpart, control max depth via maxdepth parameter
fit <- rpart(Purchased ~ Gender + Age + EstimatedSalary,
             data = train_data,
             method = "class",
             control = rpart.control(maxdepth = 3))

# Predict class labels on train and test
train_pred_class <- predict(fit, newdata = train_data, type = "class")
test_pred_class <- predict(fit, newdata = test_data, type = "class")

# Predict probabilities for class "1" (assuming positive class is "1")
train_pred_prob <- predict(fit, newdata = train_data, type = "prob")[, "1"]
test_pred_prob <- predict(fit, newdata = test_data, type = "prob")[, "1"]

# Calculate accuracy
acc_train <- mean(train_pred_class == train_data$Purchased)
acc_test <- mean(test_pred_class == test_data$Purchased)

# Calculate AUC
auc_train <- roc(train_data$Purchased, train_pred_prob)$auc
auc_test <- roc(test_data$Purchased, test_pred_prob)$auc

cat(sprintf("In-sample Accuracy: %.4f\n", acc_train))
cat(sprintf("In-sample AUC: %.4f\n", auc_train))
cat(sprintf("Out-of-sample Accuracy: %.4f\n", acc_test))
cat(sprintf("Out-of-sample AUC: %.4f\n", auc_test))

# Plot the classification tree
rpart.plot(fit, main = "Classification Tree", type = 3, extra = 104, fallen.leaves = TRUE)
```






### **Random Forest**

```{r, message=FALSE, warning=FALSE}
# Continuous Response

# Load necessary libraries
library(randomForest)
library(caret)  # for data splitting

# Assume your data.frame is called df and all variables are numeric as in Python

# Features and target
X <- df[, c('age', 'study_hours_per_day', 'social_media_hours', 'netflix_hours',
            'part_time_job', 'attendance_percentage', 'sleep_hours',
            'exercise_frequency', 'mental_health_rating', 'extracurricular_participation',
            'genderMale', 'genderOther', 'diet_qualityGood', 'diet_qualityPoor',
            'internet_qualityGood', 'internet_qualityPoor')]

y <- df$exam_score

# Combine X and y for caret's createDataPartition
data_rf <- data.frame(X, exam_score = y)

# Split data (70% train, 30% test)
set.seed(123)
train_index <- createDataPartition(data_rf$exam_score, p = 0.7, list = FALSE)
train_data <- data_rf[train_index, ]
test_data <- data_rf[-train_index, ]

# Fit random forest regressor
rf_model <- randomForest(exam_score ~ ., data = train_data, ntree = 100, importance = TRUE)

# Predict on train and test
train_pred <- predict(rf_model, newdata = train_data)
test_pred <- predict(rf_model, newdata = test_data)

# Calculate RMSE
rmse <- function(actual, predicted) {
  sqrt(mean((actual - predicted)^2))
}

rmse_train <- rmse(train_data$exam_score, train_pred)
rmse_test <- rmse(test_data$exam_score, test_pred)

cat("In-sample RMSE:", round(rmse_train, 4), "\n")
cat("Out-of-sample RMSE:", round(rmse_test, 4), "\n")
```

```{r, message=FALSE}
# Binary Response

# Load libraries
library(randomForest)
library(caret)
library(pROC)  # for AUC

# Assume your dataframe is ads and variables are numeric/factors as needed

# Features and target
X <- ads[, c('Gender', 'Age', 'EstimatedSalary')]  # Make sure Gender is numeric/factor
y <- ads$Purchased  # binary factor or 0/1

# Combine X and y for splitting
data_rf <- data.frame(X, Purchased = y)

# Train-test split (70%-30%)
set.seed(123)
train_index <- createDataPartition(data_rf$Purchased, p = 0.7, list = FALSE)
train_data <- data_rf[train_index, ]
test_data <- data_rf[-train_index, ]

# Train random forest classifier
rf_model <- randomForest(Purchased ~ ., data = train_data, ntree = 100)

# Predict classes
train_pred <- predict(rf_model, train_data)
test_pred <- predict(rf_model, test_data)

# Predict probabilities (needed for AUC)
train_proba <- predict(rf_model, train_data, type = "prob")[, 2]
test_proba <- predict(rf_model, test_data, type = "prob")[, 2]

# Accuracy
acc_train <- mean(train_pred == train_data$Purchased)
acc_test <- mean(test_pred == test_data$Purchased)

# AUC
auc_train <- roc(train_data$Purchased, train_proba)$auc
auc_test <- roc(test_data$Purchased, test_proba)$auc

cat("In-sample Accuracy:", round(acc_train, 4), "\n")
cat("In-sample AUC:", round(auc_train, 4), "\n")
cat("Out-of-sample Accuracy:", round(acc_test, 4), "\n")
cat("Out-of-sample AUC:", round(auc_test, 4), "\n\n")

# Classification report (precision, recall, F1)
conf_mat <- confusionMatrix(test_pred, test_data$Purchased, positive = "1")
print(conf_mat)
```






### **Boosting**

```{r, message=FALSE, warning=FALSE}
# Continuous Response

# Load libraries
library(xgboost)
library(caret)
library(Metrics)  # for rmse calculation

# Prepare your data: X numeric matrix, y numeric vector
X <- df[, c('age', 'study_hours_per_day', 'social_media_hours', 'netflix_hours',
            'part_time_job', 'attendance_percentage', 'sleep_hours',
            'exercise_frequency', 'mental_health_rating', 'extracurricular_participation',
            'genderMale', 'genderOther', 'diet_qualityGood', 'diet_qualityPoor',
            'internet_qualityGood', 'internet_qualityPoor')]
y <- df$exam_score

# Train-test split (70%-30%)
set.seed(42)
train_idx <- createDataPartition(y, p = 0.7, list = FALSE)
X_train <- as.matrix(X[train_idx, ])
y_train <- y[train_idx]
X_test <- as.matrix(X[-train_idx, ])
y_test <- y[-train_idx]

# Convert to xgb.DMatrix (efficient data structure for xgboost)
dtrain <- xgb.DMatrix(data = X_train, label = y_train)
dtest <- xgb.DMatrix(data = X_test, label = y_test)

# Set parameters for regression
params <- list(
  objective = "reg:squarederror",  # regression task with squared error loss
  eval_metric = "rmse"
)

# Train boosted trees model
set.seed(123)
xgb_model <- xgb.train(
  params = params,
  data = dtrain,
  nrounds = 100,               # number of boosting rounds (trees)
  watchlist = list(train = dtrain),
  verbose = 0
)

# Predict
y_train_pred <- predict(xgb_model, dtrain)
y_test_pred <- predict(xgb_model, dtest)

# Compute RMSE
rmse_train <- rmse(y_train, y_train_pred)
rmse_test <- rmse(y_test, y_test_pred)

cat("In-sample RMSE:", round(rmse_train, 4), "\n")
cat("Out-of-sample RMSE:", round(rmse_test, 4), "\n")
```

```{r, message=FALSE}
# Binary Response

# Load libraries
library(xgboost)
library(caret)
library(pROC)

# Prepare your data
X <- ads[, c('Gender', 'Age', 'EstimatedSalary')]  # numeric predictors only
y <- as.numeric(as.character(ads$Purchased))  # binary response (0/1 or factor with two levels)

# If 'Gender' is a factor, convert to numeric (e.g., one-hot encoding or numeric encoding)
# For simplicity, let's convert factor to numeric:
if (is.factor(X$Gender)) {
  X$Gender <- as.numeric(as.factor(X$Gender))
}

# Train-test split (70%-30%)
set.seed(123)
train_idx <- createDataPartition(y, p = 0.7, list = FALSE)
X_train <- as.matrix(X[train_idx, ])
y_train <- y[train_idx]
X_test <- as.matrix(X[-train_idx, ])
y_test <- y[-train_idx]

# Convert to xgb.DMatrix
dtrain <- xgb.DMatrix(data = X_train, label = y_train)
dtest <- xgb.DMatrix(data = X_test, label = y_test)

# Set parameters for binary classification
params <- list(
  objective = "binary:logistic",  # binary classification with logistic loss
  eval_metric = "auc",
  max_depth = 3,
  eta = 0.1  # learning rate
)

# Train the model
set.seed(123)
xgb_model <- xgb.train(
  params = params,
  data = dtrain,
  nrounds = 100,
  watchlist = list(train = dtrain),
  verbose = 0
)

# Predict probabilities
y_train_proba <- predict(xgb_model, dtrain)
y_test_proba <- predict(xgb_model, dtest)

# Convert probabilities to class labels using 0.5 cutoff
y_train_pred <- ifelse(y_train_proba > 0.5, 1, 0)
y_test_pred <- ifelse(y_test_proba > 0.5, 1, 0)

# Calculate accuracy
acc_train <- mean(y_train_pred == y_train)
acc_test <- mean(y_test_pred == y_test)

# Calculate AUC
auc_train <- roc(y_train, y_train_proba)$auc
auc_test <- roc(y_test, y_test_proba)$auc

cat("In-sample Accuracy:", round(acc_train, 4), "\n")
cat("In-sample AUC:", round(auc_train, 4), "\n")
cat("Out-of-sample Accuracy:", round(acc_test, 4), "\n")
cat("Out-of-sample AUC:", round(auc_test, 4), "\n")

# Classification report (precision, recall, F1)
conf_mat <- confusionMatrix(
  factor(y_test_pred, levels = c(0, 1)),
  factor(y_test, levels = c(0, 1)),
  positive = "1"
)
print(conf_mat)
```






### **BART**

```{r, message=FALSE, warning=FALSE}
# Continuous Response

# Load library
library(BART)

# Prepare your data: X numeric matrix, y numeric vector
X <- df[, c('age', 'study_hours_per_day', 'social_media_hours', 'netflix_hours',
            'part_time_job', 'attendance_percentage', 'sleep_hours',
            'exercise_frequency', 'mental_health_rating', 'extracurricular_participation',
            'genderMale', 'genderOther', 'diet_qualityGood', 'diet_qualityPoor',
            'internet_qualityGood', 'internet_qualityPoor')]
y <- df$exam_score

# Train-test split (70%-30%)
set.seed(42)
train_idx <- createDataPartition(y, p = 0.7, list = FALSE)
X_train <- as.matrix(X[train_idx, ])
y_train <- y[train_idx]
X_test <- as.matrix(X[-train_idx, ])
y_test <- y[-train_idx]

# Fit BART model
set.seed(123)
bart_model <- wbart(x.train = X_train, y.train = y_train, x.test = X_test)

# --- In-sample predictions ---
yhat_train_mean <- colMeans(bart_model$yhat.train)
rmse_train <- sqrt(mean((y_train - yhat_train_mean)^2))
cat("In-sample RMSE:", round(rmse_train, 4), "\n")

# --- Out-of-sample predictions ---
yhat_test_mean <- colMeans(bart_model$yhat.test)
rmse_test <- sqrt(mean((y_test - yhat_test_mean)^2))
cat("Out-of-sample RMSE:", round(rmse_test, 4), "\n")

# Optionally, credible intervals
ci_lower <- apply(bart_model$yhat.test, 2, quantile, probs = 0.025)
ci_upper <- apply(bart_model$yhat.test, 2, quantile, probs = 0.975)

# Plot actual vs predicted with CI
# plot(y_test, yhat_test_mean, xlab = "Actual", ylab = "Predicted", main = "BART Predictions")
# abline(0, 1, col = "red")
```

```{r, message=FALSE}
# Binary Response

# Load libraries
library(BART)
library(caret)
library(pROC)

# Prepare the data
X <- ads[, c('Gender', 'Age', 'EstimatedSalary')]
y <- as.numeric(as.character(ads$Purchased))  # must be binary: 0 or 1

# Convert Gender to numeric if it's a factor
if (is.factor(X$Gender)) {
  X$Gender <- as.numeric(as.factor(X$Gender))
}

# Split into training and testing sets
set.seed(123)
train_idx <- createDataPartition(y, p = 0.7, list = FALSE)
X_train <- as.matrix(X[train_idx, ])
y_train <- y[train_idx]
X_test <- as.matrix(X[-train_idx, ])
y_test <- y[-train_idx]

# Fit BART for binary response
set.seed(123)
bart_model <- pbart(x.train = X_train, y.train = y_train, x.test = X_test)

# Predicted probabilities
y_train_proba <- colMeans(bart_model$prob.train)
y_test_proba <- colMeans(bart_model$prob.test)

# Predicted class labels (using 0.5 threshold)
y_train_pred <- ifelse(y_train_proba > 0.5, 1, 0)
y_test_pred <- ifelse(y_test_proba > 0.5, 1, 0)

# Accuracy
acc_train <- mean(y_train_pred == y_train)
acc_test <- mean(y_test_pred == y_test)

# AUC
auc_train <- roc(y_train, y_train_proba)$auc
auc_test <- roc(y_test, y_test_proba)$auc

# Output results
cat("In-sample Accuracy:", round(acc_train, 4), "\n")
cat("In-sample AUC:", round(auc_train, 4), "\n")
cat("Out-of-sample Accuracy:", round(acc_test, 4), "\n")
cat("Out-of-sample AUC:", round(auc_test, 4), "\n")

# Classification report (precision, recall, F1)
conf_mat <- confusionMatrix(
  factor(y_test_pred, levels = c(0, 1)),
  factor(y_test, levels = c(0, 1)),
  positive = "1"
)
print(conf_mat)
```






### **Neural Network**

```{r, message=FALSE, warning=FALSE}
# Continuous Response

# Load necessary libraries
library(nnet)     # for neural network
library(caret)    # for train/test split and preprocessing
library(Metrics)  # for RMSE
library(dplyr)

# Prepare the data
X <- df %>%
  select(age, study_hours_per_day, social_media_hours, netflix_hours,
         part_time_job, attendance_percentage, sleep_hours,
         exercise_frequency, mental_health_rating, extracurricular_participation,
         genderMale, genderOther, diet_qualityGood, diet_qualityPoor,
         internet_qualityGood, internet_qualityPoor)

y <- df$exam_score

# Train/test split
set.seed(123)
train_index <- createDataPartition(y, p = 0.7, list = FALSE)
X_train <- X[train_index, ]
X_test  <- X[-train_index, ]
y_train <- y[train_index]
y_test  <- y[-train_index]

# Standardize the predictors (recommended for neural nets)
preproc <- preProcess(X_train, method = c("center", "scale"))
X_train_scaled <- predict(preproc, X_train)
X_test_scaled  <- predict(preproc, X_test)

# Fit neural network
set.seed(123)
nn_model <- nnet(
  x = as.matrix(X_train_scaled),
  y = y_train,
  size = 10,         # number of hidden units
  linout = TRUE,     # for regression
  maxit = 500        # max iterations
)

# Predictions
y_train_pred <- predict(nn_model, as.matrix(X_train_scaled))
y_test_pred  <- predict(nn_model, as.matrix(X_test_scaled))

# Evaluation
train_rmse <- rmse(y_train, y_train_pred)
test_rmse  <- rmse(y_test, y_test_pred)
train_r2   <- 1 - sum((y_train - y_train_pred)^2) / sum((y_train - mean(y_train))^2)
test_r2    <- 1 - sum((y_test - y_test_pred)^2) / sum((y_test - mean(y_test))^2)

cat("Train RMSE:", round(train_rmse, 4), "\n")
cat("Test RMSE:", round(test_rmse, 4), "\n")
```

```{r, message=FALSE, warning=FALSE}
# Binary Response

# Load necessary libraries
library(nnet)     # for neural network modeling
library(caret)    # for data partitioning
library(pROC)     # for AUC
library(dplyr)

# Define X and y
X <- ads %>%
  select(Gender, Age, EstimatedSalary)

# Ensure Gender is numeric
if (is.factor(X$Gender)) {
  X$Gender <- as.numeric(as.factor(X$Gender))
}

y <- as.numeric(as.character(ads$Purchased))  # Binary response (0/1)

# Train-test split
set.seed(123)
train_index <- createDataPartition(y, p = 0.7, list = FALSE)
X_train <- X[train_index, ]
X_test  <- X[-train_index, ]
y_train <- y[train_index]
y_test  <- y[-train_index]

# Standardize features (important for neural nets)
preproc <- preProcess(X_train, method = c("center", "scale"))
X_train_scaled <- predict(preproc, X_train)
X_test_scaled  <- predict(preproc, X_test)

# Fit neural network classifier
set.seed(42)
nn_clf <- nnet(
  x = as.matrix(X_train_scaled),
  y = y_train,
  size = 10,          # number of hidden units
  linout = FALSE,     # FALSE = classification
  maxit = 500,        # max iterations
  trace = FALSE       # suppress output
)

# Predictions
y_train_proba <- predict(nn_clf, as.matrix(X_train_scaled), type = "raw")
y_test_proba  <- predict(nn_clf, as.matrix(X_test_scaled), type = "raw")

# Convert probabilities to class labels using 0.5 cutoff
y_train_pred <- ifelse(y_train_proba > 0.5, 1, 0)
y_test_pred  <- ifelse(y_test_proba > 0.5, 1, 0)

# Evaluation
acc_train <- mean(y_train_pred == y_train)
acc_test  <- mean(y_test_pred == y_test)
auc_train <- roc(y_train, y_train_proba)$auc
auc_test  <- roc(y_test, y_test_proba)$auc

cat("Train Accuracy:", round(acc_train, 4), "\n")
cat("Train AUC:", round(auc_train, 4), "\n")
cat("Test Accuracy:", round(acc_test, 4), "\n")
cat("Test AUC:", round(auc_test, 4), "\n")

conf_mat <- confusionMatrix(
  factor(y_test_pred, levels = c(0, 1)),
  factor(y_test, levels = c(0, 1)),
  positive = "1"
)
print(conf_mat)
```


